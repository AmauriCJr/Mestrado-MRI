{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmasF4qVHXbc"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import cupy\n",
        "except:\n",
        "    pass\n",
        "import datetime\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "#from mri_cs import column2matrix, matrix2column, prefiltering, radial_lines_samples_rows\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import pydot\n",
        "from scipy.io import loadmat\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBCPl3Q8PxYy",
        "outputId": "eb3874b5-90f6-4a0b-ed23-dec6045f66c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjxIqTBgKc8P"
      },
      "outputs": [],
      "source": [
        "mode = 'test'\n",
        "save_checkpoint = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlrWWr2lANID"
      },
      "outputs": [],
      "source": [
        "# Conta o n√∫mero de arquivos em uma pasta\n",
        "\n",
        "def count_files(folder):\n",
        "    items = os.listdir(folder)\n",
        "\n",
        "    files = [item for item in items if os.path.isfile(os.path.join(folder, item))]\n",
        "\n",
        "    return len(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJWKGv5ZKf6y",
        "outputId": "561d6738-30e9-4feb-888f-43e4c3e10203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train images:  1500\n"
          ]
        }
      ],
      "source": [
        "if mode == 'train' or mode == 'test':\n",
        "    show_intermediate_images = False\n",
        "    show_predicted_images_after_training = False\n",
        "\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "    dataset_name = \"birn_anatomical_part\"\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "    dataset_path = '/content/gdrive/MyDrive/Mestrado/CoÃÅdigos/datasets/' + dataset_name + '/'\n",
        "    n_cont = count_files(dataset_path + 'train')\n",
        "    print(\"Number of train images: \", n_cont)\n",
        "\n",
        "\n",
        "if mode == 'train':\n",
        "    sample_image = tf.io.read_file(dataset_path + 'train/1.png')\n",
        "    sample_image = tf.io.decode_png(sample_image, channels=3)\n",
        "    print(sample_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1B5vdE3JiRD"
      },
      "outputs": [],
      "source": [
        "if mode == 'train':\n",
        "    if show_intermediate_images:\n",
        "        plt.figure()\n",
        "        plt.imshow(sample_image)\n",
        "\n",
        "def load(image_file):\n",
        "    # Read and decode an image file to a uint8 tensor\n",
        "    print(\"Start Load\")\n",
        "    print(\"real_file type: \", type(image_file))\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.io.decode_png(image, channels=3)\n",
        "    print(\"END STEP 1 LOAD\")\n",
        "\n",
        "    # Split each image tensor into two tensors:\n",
        "    # - one with a real building facade image\n",
        "    # - one with an architecture label image\n",
        "    w = tf.shape(image)[1]\n",
        "    w = w // 2\n",
        "    input_image = image[:, w:, :]\n",
        "    real_image = image[:, :w, :]\n",
        "\n",
        "    # Convert both images to float32 tensors\n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "    file_path = image_file\n",
        "    print(\"input_image type: \", type(input_image))\n",
        "    print(\"real_image type: \", type(real_image))\n",
        "    print(\"file_path type: \", type(file_path))\n",
        "    print(\"END STEP 2 LOAD\")\n",
        "    return input_image, real_image, file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Fabh-5K0ke",
        "outputId": "6ef82d5c-79cb-4f13-d534-da559e71ec5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Load\n",
            "real_file type:  <class 'str'>\n",
            "END STEP 1 LOAD\n",
            "input_image type:  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "real_image type:  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "file_path type:  <class 'str'>\n",
            "END STEP 2 LOAD\n",
            "Image Height:  512\n",
            "Image Width:  512\n"
          ]
        }
      ],
      "source": [
        "if mode == 'train' or mode == 'test':\n",
        "    input1, output1, img_path = load(dataset_path + 'test/1.png')\n",
        "    IMG_HEIGHT, IMG_WIDTH = input1.shape[:2]\n",
        "    print(\"Image Height: \", IMG_HEIGHT)\n",
        "    print(\"Image Width: \", IMG_WIDTH)\n",
        "    if show_intermediate_images:\n",
        "        plt.figure()\n",
        "        plt.imshow(input1 / 255.0)\n",
        "        plt.title(\"Example of image to be used in the cGAN input\")\n",
        "        plt.show()\n",
        "        plt.figure()\n",
        "        plt.imshow(output1 / 255.0)\n",
        "        plt.title(\"Example of image to be generated in the cGAN output\")\n",
        "        plt.show()\n",
        "\n",
        "if mode == 'train':\n",
        "    inp, re, img_path = load(dataset_path + 'train/1.png')\n",
        "    print(\"Input Shape: \", inp.shape)\n",
        "    if show_intermediate_images:\n",
        "        # Casting to int for matplotlib to display the images\n",
        "        plt.figure()\n",
        "        plt.imshow(inp / 255.0)\n",
        "        plt.title(\"Example of image to be used in the cGAN input\")\n",
        "        plt.show()\n",
        "        plt.figure()\n",
        "        plt.imshow(re / 255.0)\n",
        "        plt.title(\"Example of image to be generated in the cGAN output\")\n",
        "        plt.show()\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "    # The facade training set consist of 400 images\n",
        "    BUFFER_SIZE = int(n_cont)\n",
        "    # The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n",
        "    BATCH_SIZE = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3PH_luIK1XH"
      },
      "outputs": [],
      "source": [
        "# Esse conjunto de fun√ß√µes aumenta o tamanho das imagens e depois corta trechos da imagem aumentada do tamanho da imagem original, isso permite\n",
        "#maior variedade de dados de treinamento inserindo leves varia√ßoes na imagem\n",
        "\n",
        "def resize(input_image, real_image, height, width):\n",
        "    input_image = tf.image.resize(input_image, [height, width],\n",
        "    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    real_image = tf.image.resize(real_image, [height, width],\n",
        "    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def random_crop(input_image, real_image):\n",
        "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "    cropped_image = tf.image.random_crop(\\\n",
        "    stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    return cropped_image[0], cropped_image[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhOyfpj5LOTU"
      },
      "outputs": [],
      "source": [
        "# Faz um teste, abrindo a segunda imagem e realizando as oprea√ß√µes resize e random_crop\n",
        "if mode == 'train':\n",
        "    input1, output1, img_path = load(dataset_path + 'train/2.png')\n",
        "    input1, output1 = resize(input1, output1, IMG_HEIGHT + 30, IMG_WIDTH + 30)\n",
        "    input1, output1 = random_crop(input1, output1)\n",
        "    if show_intermediate_images:\n",
        "        plt.figure()\n",
        "        plt.imshow(input1 / 255.0)\n",
        "        plt.title(\"Example of image to be used in the cGAN input\")\n",
        "        plt.show()\n",
        "        plt.figure()\n",
        "        plt.imshow(output1 / 255.0)\n",
        "        plt.title(\"Example of image to be generated in the cGAN output\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2LCcxiXLP0Q"
      },
      "outputs": [],
      "source": [
        "# Normaliza os valores para ficarem entre -1 e 1\n",
        "def normalize(input_image, real_image):\n",
        "\n",
        "    input_image = (input_image / 127.5) - 1\n",
        "    real_image = (real_image / 127.5) - 1\n",
        "\n",
        "    return input_image, real_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TptePVoHLRnC"
      },
      "outputs": [],
      "source": [
        "# Usa as fun√ß√µes resize e random_crop  para aumentar a variedade das imagens al√©m de espelhar algumas imagens.\n",
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "\n",
        "    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT + 30, IMG_WIDTH + 30)\n",
        "    input_image, real_image = random_crop(input_image, real_image)\n",
        "\n",
        "    # Aleatoriamente espelha algumas imagens em volta do eixo vertical, aumentando a variedade e diminuindo overfitting\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        real_image = tf.image.flip_left_right(real_image)\n",
        "    return input_image, real_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZVgJZNTHhFe"
      },
      "outputs": [],
      "source": [
        "if mode == 'train':\n",
        "    data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "                                            tf.keras.layers.RandomRotation(0.2),])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsfoHL2FHiBD"
      },
      "outputs": [],
      "source": [
        "def augment_images(input, target):\n",
        "    input = data_augmentation(input)\n",
        "    target = data_augmentation(target)\n",
        "    return input, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xSBufGXLRnf"
      },
      "outputs": [],
      "source": [
        "# Visualiza a imagem ap√≥s aplicar a fun√ß√£o random_jitter\n",
        "if mode == 'train':\n",
        "    if show_intermediate_images:\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        for i in range(4):\n",
        "            rj_inp, rj_re = random_jitter(inp, re)\n",
        "            plt.subplot(2, 2, i + 1)\n",
        "            plt.imshow(rj_inp / 255.0)\n",
        "            plt.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmK3W0OQLUIR"
      },
      "outputs": [],
      "source": [
        "# As tr√™s fun√ß√µes abaixo carregam os conjuntos de dados de treino, teste e valida√ß√£o respectivamente, realizando as opera√ß√µes de random_jitter e normaliza√ß√£o\n",
        "def load_image_train(image_file):\n",
        "    input_image, real_image, file_path = load(image_file)\n",
        "    input_image, real_image = random_jitter(input_image, real_image)\n",
        "    # input_image, real_image = augment_images(input_image, real_image) Rotacionar as imagens estava criando muito ru√≠do e atrapalhando o treinamento pois as imagens sempre est√£o na mesma posi√ß√£o\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "    return input_image, real_image, file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc_sEgpMLXQq"
      },
      "outputs": [],
      "source": [
        "def load_image_test(image_file):\n",
        "    input_image, real_image, file_path = load(image_file)\n",
        "    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT, IMG_WIDTH)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "    return input_image, real_image, file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um5KykRoEN3c"
      },
      "outputs": [],
      "source": [
        "def load_image_val(image_file):\n",
        "    input_image, real_image, file_path = load(image_file)\n",
        "    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT, IMG_WIDTH)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "    return input_image, real_image, file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L_-B6DiLa6M",
        "outputId": "ead1df16-b8a9-491a-ba30-1ade4c737792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Load\n",
            "real_file type:  <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "END STEP 1 LOAD\n",
            "input_image type:  <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "real_image type:  <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "file_path type:  <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "END STEP 2 LOAD\n"
          ]
        }
      ],
      "source": [
        "# Mapeia e separa os conjuntos em batches\n",
        "if mode == 'train':\n",
        "    train_dataset = tf.data.Dataset.list_files(dataset_path + 'train/*.png')\n",
        "    train_dataset = train_dataset.map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    try:\n",
        "        val_dataset = tf.data.Dataset.list_files(dataset_path + 'val/*.png')\n",
        "    except tf.errors.InvalidArgumentError:\n",
        "        print(\"ERROR\")\n",
        "    val_dataset = val_dataset.map(load_image_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "    val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "    try:\n",
        "        test_dataset = tf.data.Dataset.list_files(dataset_path + 'test/*.png')\n",
        "    except tf.errors.InvalidArgumentError:\n",
        "        print(\"ERROR\")\n",
        "    test_dataset = test_dataset.map(load_image_test)\n",
        "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "    test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "if mode == 'train':\n",
        "    OUTPUT_CHANNELS = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Waq2F6x5LhYj"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o que cria o modelo downsample\n",
        "def downsample(filters, size, apply_batchnorm = True, kernel_regularizer=None):\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "\n",
        "    result.add(tf.keras.layers.Conv2D(filters, size, strides = 2, padding = 'same',\n",
        "                                        kernel_initializer = initializer,\n",
        "                                        kernel_regularizer = kernel_regularizer,\n",
        "                                        use_bias = not apply_batchnorm))\n",
        "\n",
        "    if apply_batchnorm:\n",
        "        result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z4CE2EZLh5a"
      },
      "outputs": [],
      "source": [
        "# Apresenta uma imagem ap√≥s aplicar o downsample\n",
        "\n",
        "if mode == 'train':\n",
        "    down_model = downsample(3, 4)\n",
        "    down_result = down_model(tf.expand_dims(inp, 0))\n",
        "    print(inp.shape)\n",
        "    print(down_result.shape)\n",
        "    print(np.min(inp))\n",
        "    print(np.max(inp))\n",
        "    print(np.min(down_result))\n",
        "    print(np.max(down_result))\n",
        "    x = down_result[0, :, :, :]\n",
        "    x -= np.min(x)\n",
        "    x /= np.max(x)\n",
        "    print(np.min(inp))\n",
        "    print(np.max(inp))\n",
        "    print(np.min(x))\n",
        "    print(np.max(x))\n",
        "    if show_intermediate_images:\n",
        "        plt.imshow(inp / 255.0)\n",
        "        plt.imshow(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH5P3QdiLkDO"
      },
      "outputs": [],
      "source": [
        "# Apresenta uma imagem que ser√° usada como input da GAN, com a realiza√ß√£o de opera√ß√µes de resize e random_crop\n",
        "# Tamb√©m apresenta uma imagem ap√≥s a realiza√ß√£o do downsample\n",
        "\n",
        "if mode == 'train':\n",
        "    input1, output1, img_path = load(dataset_path + 'train/1.png')\n",
        "    input1, output1 = resize(input1, output1, IMG_HEIGHT + 30, IMG_WIDTH + 30)\n",
        "    input1, output1 = random_crop(input1, output1)\n",
        "    if show_intermediate_images:\n",
        "        plt.figure()\n",
        "        plt.imshow(input1 / 255.0)\n",
        "        plt.title(\"Example of image to be used in the cGAN input\")\n",
        "        plt.show()\n",
        "        input1, output1 = normalize(input1, output1)\n",
        "        down_result = down_model(tf.expand_dims(input1, 0))\n",
        "        # plt.figure()\n",
        "        # plt.imshow((down_result + 1) / 2 * 255.0)\n",
        "        # plt.title(\"Example of the image after the downsample model (before training)\")\n",
        "        # plt.show()\n",
        "        print(input1.shape)\n",
        "        print(down_result.shape)\n",
        "        x = np.zeros(shape = (down_result.shape[1], down_result.shape[2], down_result.shape[3]))\n",
        "        print(x.shape)\n",
        "        x[:, :, :] = down_result[0, :, :, :]\n",
        "        plt.figure()\n",
        "        plt.imshow(x)\n",
        "        plt.title(\"Example of the downsample module output (before training)\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyu1p7FZLl9M"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o que cria o modelo upsample\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "\n",
        "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                padding='same',\n",
        "                kernel_initializer=initializer,\n",
        "                use_bias=False))\n",
        "\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "        result.add(tf.keras.layers.ReLU())\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diQzquFmLuVJ"
      },
      "outputs": [],
      "source": [
        "# Cria um modelo upsample\n",
        "if mode == 'train':\n",
        "    up_model = upsample(3, 4)\n",
        "    up_result = up_model(down_result)\n",
        "    print (up_result.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_Cxk78ZLwWR"
      },
      "outputs": [],
      "source": [
        "# Cria o gerador baseado em um modelo U-net com uma sequ√™ncia de downsamples e upsamples que evidencia as caracter√≠sticas da imagem\n",
        "def Generator():\n",
        "    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3])  # Entrada do modelo\n",
        "\n",
        "    # Define o down_stack (as camadas de downsampling)\n",
        "    down_stack = [\n",
        "        downsample(64, 4, apply_batchnorm=False),  # (batch_size, IMG_HEIGHT/2, IMG_WIDTH/2, 64)\n",
        "        downsample(128, 4),                        # (batch_size, IMG_HEIGHT/4, IMG_WIDTH/4, 128)\n",
        "        downsample(256, 4),                        # (batch_size, IMG_HEIGHT/8, IMG_WIDTH/8, 256)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/16, IMG_WIDTH/16, 512)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/32, IMG_WIDTH/32, 512)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/64, IMG_WIDTH/64, 512)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/128, IMG_WIDTH/128, 512)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/256, IMG_WIDTH/256, 512)\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Passa a entrada pelas camadas de downsampling\n",
        "    x = inputs\n",
        "    skips = []  # Para armazenar conex√µes de salto (skip connections)\n",
        "    for down in down_stack:\n",
        "        x = down(x)  # Chama cada camada no down_stack\n",
        "        skips.append(x)\n",
        "\n",
        "    # Remove a √∫ltima conex√£o de salto, pois ela n√£o √© usada no upsampling\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Define o up_stack (as camadas de upsampling)\n",
        "    up_stack = [\n",
        "        upsample(512, 4, apply_dropout=True),  # (batch_size, IMG_HEIGHT/128, IMG_WIDTH/128, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (batch_size, IMG_HEIGHT/64, IMG_WIDTH/64, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (batch_size, IMG_HEIGHT/32, IMG_WIDTH/32, 1024)\n",
        "        upsample(512, 4),                      # (batch_size, IMG_HEIGHT/16, IMG_WIDTH/16, 1024)\n",
        "        upsample(256, 4),                      # (batch_size, IMG_HEIGHT/8, IMG_WIDTH/8, 512)\n",
        "        upsample(128, 4),                      # (batch_size, IMG_HEIGHT/4, IMG_WIDTH/4, 256)\n",
        "        upsample(64, 4),                       # (batch_size, IMG_HEIGHT/2, IMG_WIDTH/2, 128)\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    # Passa pelos upsampling layers e conecta com os skips\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = tf.keras.layers.Concatenate()([x, skip])\n",
        "\n",
        "    # √öltima camada de sa√≠da\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv2DTranspose(\n",
        "        3, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh',\n",
        "        kernel_regularizer=tf.keras.regularizers.L2(1e-4)  # Adiciona regulariza√ß√£o L2\n",
        "    )  # (batch_size, IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywZUj1QeL74Q"
      },
      "outputs": [],
      "source": [
        "# Cria uma visualiza√ß√£o gr√°fica do modelo gerador\n",
        "# if mode == 'train':\n",
        "#     generator = Generator()\n",
        "#     tf.keras.utils.plot_model(generator, to_file = 'generator.png', show_shapes=True, dpi=64)\n",
        "#     if show_intermediate_images:\n",
        "#         x = plt.imread('generator.png')\n",
        "#         plt.imshow(x, cmap = 'gray')\n",
        "#         plt.show()\n",
        "\n",
        "\n",
        "# Aplica o modelo a uma imagem exemplo e apresenta o resultado\n",
        "if mode == 'train':\n",
        "    generator = Generator()\n",
        "    generator.summary()\n",
        "    gen_output = generator(inp[tf.newaxis, ...], training=False)\n",
        "    if show_intermediate_images:\n",
        "        plt.imshow(gen_output[0, ...])\n",
        "\n",
        "\n",
        "if mode == 'train':\n",
        "    plot_path = os.path.join('/content/gdrive/MyDrive/Mestrado/C√≥digos/Plot/', \"unet_diagram.png\")\n",
        "    plot_model(generator, to_file=plot_path, show_shapes=True, expand_nested=True)\n",
        "\n",
        "    print(f\"Diagrama salvo em: {plot_path}\")\n",
        "\n",
        "\n",
        "if mode == 'train':\n",
        "    LAMBDA = 150\n",
        "\n",
        "if mode == 'train':\n",
        "    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtB0qur8blMU"
      },
      "outputs": [],
      "source": [
        "# retorna os valores de loss do generator que s√£o usados para ajustar a rede\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        " gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        " l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        " total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        " return total_gen_loss, gan_loss, l1_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhmchusRMB9N"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o que cria o modelo discriminador\n",
        "def Discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    # Define as entradas com base em IMG_HEIGHT e IMG_WIDTH\n",
        "    inp = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3], name='input_image')\n",
        "    tar = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3], name='target_image')\n",
        "\n",
        "    # Calcula a diferen√ßa absoluta entre as imagens\n",
        "    diff = tf.keras.layers.Subtract()([tar, inp])  # Calcula tar - inp\n",
        "\n",
        "    # Concatena as imagens de entrada, alvo e a diferen√ßa\n",
        "    x = tf.keras.layers.concatenate([inp, tar, diff])  # (batch_size, IMG_HEIGHT, IMG_WIDTH, 9)\n",
        "\n",
        "    # Define o down_stack com dropout e regulariza√ß√£o L2\n",
        "    down1 = downsample(64, 4, apply_batchnorm=False)(x)\n",
        "    down2 = tf.keras.layers.Dropout(0.5)(downsample(128, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down1))\n",
        "    down3 = tf.keras.layers.Dropout(0.5)(downsample(256, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down2))\n",
        "    down4 = downsample(512, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down3)\n",
        "    down5 = tf.keras.layers.Dropout(0.5)(downsample(512, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down4))\n",
        "    down6 = downsample(512, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down5)\n",
        "    down7 = tf.keras.layers.Dropout(0.5)(downsample(512, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down6))\n",
        "\n",
        "    # Zero padding para manter as dimens√µes ao aplicar convolu√ß√µes finais\n",
        "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down7)\n",
        "    conv = tf.keras.layers.Conv2D(\n",
        "        512, 4, strides=1, kernel_initializer=initializer, use_bias=False,\n",
        "        kernel_regularizer=tf.keras.regularizers.L2(1e-4)\n",
        "    )(zero_pad1)\n",
        "\n",
        "    # Batch normalization e ativa√ß√£o Leaky ReLU\n",
        "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "    # Segunda camada de zero padding e convolu√ß√£o final para classificar real/fake\n",
        "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)\n",
        "    last = tf.keras.layers.Conv2D(\n",
        "        1, 4, strides=1, kernel_initializer=initializer,\n",
        "        kernel_regularizer=tf.keras.regularizers.L2(1e-4)\n",
        "    )(zero_pad2)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtIbZqUnMEfa"
      },
      "outputs": [],
      "source": [
        "# visualiza o modelo discriminador de forma gr√°fica\n",
        "if mode == 'train':\n",
        "    discriminator = Discriminator()\n",
        "    discriminator.summary()\n",
        "#     plot_path = os.path.join('/content/gdrive/MyDrive/Mestrado/C√≥digos/Plot/', \"disc_diagram.png\")\n",
        "#     plot_model(discriminator, to_file=plot_path, show_shapes=True, expand_nested=True)\n",
        "\n",
        "#     print(f\"Diagrama salvo em: {plot_path}\")\n",
        "\n",
        "\n",
        "# Apresenta a saida do discriminador de forma gr√°fica\n",
        "# if mode == 'train':\n",
        "#     disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)\n",
        "#     if show_intermediate_images:\n",
        "#         plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
        "#         plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1NQ2Hy4MIsF"
      },
      "outputs": [],
      "source": [
        "# Calcula a perda (loss) do modelo discriminador\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        " real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        " generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        " total_disc_loss = real_loss + generated_loss\n",
        "\n",
        " return total_disc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2D9201kMNM5"
      },
      "outputs": [],
      "source": [
        "# Inst√¢ncia o otimizador Adam para os modelos\n",
        "\n",
        "if mode == 'train':\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "\n",
        "# Cria um objeto que salva o estado dos modelos e dos otimizadores em checkpoints\n",
        "if mode == 'train':\n",
        "    checkpoint_dir = '/content/gdrive/MyDrive/Mestrado/C√≥digos/Checkpoints'\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                    discriminator_optimizer=discriminator_optimizer,\n",
        "                                    generator=generator,\n",
        "                                    discriminator=discriminator)\n",
        "\n",
        "\n",
        "    # latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    # if latest_checkpoint and os.path.exists(latest_checkpoint + \".index\"):\n",
        "    #     checkpoint.restore(latest_checkpoint).expect_partial()\n",
        "    #     print(f\"Checkpoint restored from: {latest_checkpoint}\")\n",
        "    # else:\n",
        "    #     print(\"Checkpoint not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHNdfo4zMOvF"
      },
      "outputs": [],
      "source": [
        "# Gera o conjunto de imagens resultado em uma √∫nica imagem\n",
        "\n",
        "def generate_images(model, test_input, tar, save_path):\n",
        " prediction = model(test_input, training=True)\n",
        " plt.figure(figsize=(15, 15))\n",
        "\n",
        " display_list = [test_input[0], tar[0], prediction[0]]\n",
        " title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        " for i in range(3):\n",
        "     plt.subplot(1, 3, i+1)\n",
        "     plt.title(title[i])\n",
        "     # Getting the pixel values in the [0, 1] range to plot.\n",
        "     plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "     plt.axis('off')\n",
        "     #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6QSlbc6MQkb"
      },
      "outputs": [],
      "source": [
        "def generate_images_file(model, test_input, tar, file_name, n, comp = 0):\n",
        "    prediction = model(test_input, training=True)\n",
        "\n",
        "    display_list = [test_input[0], tar[0], prediction[0]]\n",
        "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "    # üîπ Salvando as imagens individuais no tamanho correto (512x512)\n",
        "    for i in range(3):\n",
        "        save_path = f\"{file_name}_{title[i]}.png\"\n",
        "        mpimg.imsave(save_path, display_list[i].numpy() * 0.5 + 0.5, cmap='gray')\n",
        "\n",
        "    # üîπ Criando a imagem combinada com as 3 imagens lado a lado\n",
        "\n",
        "    if comp == 1:\n",
        "        for i in range(3):\n",
        "            plt.subplot(1, 3, i+1)\n",
        "            plt.title(title[i])\n",
        "            # Getting the pixel values in the [0, 1] range to plot.\n",
        "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "            plt.axis('off')\n",
        "            if i == 2:\n",
        "                plt.savefig(file_name + '.png', dpi=300, bbox_inches = 'tight')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9UsFLmLMT3E"
      },
      "outputs": [],
      "source": [
        "# if mode == 'train':\n",
        "#     if show_intermediate_images:\n",
        "#         for example_input, example_target in test_dataset.take(1):\n",
        "#          generate_images(generator, example_input, example_target)\n",
        "\n",
        "# Cria logs com detalhamento dos treinamentos\n",
        "if mode == 'train':\n",
        "    log_dir=\"logs/\"\n",
        "    summary_writer = tf.summary.create_file_writer(\n",
        "     log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chK8H1C_MWcq"
      },
      "outputs": [],
      "source": [
        "# Realiza o treinamento do modelo\n",
        "@tf.function\n",
        "def train_step(input_image, target, step):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Gera a imagem de sa√≠da do gerador\n",
        "        gen_output = generator(input_image, training=True)\n",
        "\n",
        "        # Recebe os pares de imagem reais e falsos com os respectivos r√≥tulos\n",
        "        disc_real_output = discriminator([input_image, target], training=True)\n",
        "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
        "\n",
        "        # Calcula as perdas do gerador e do discriminador\n",
        "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "        # Calcula os gradientes e aplica a otimiza√ß√£o\n",
        "        generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
        "        discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
        "\n",
        "    # Calcula a acur√°cia do discriminador para as imagens reais e geradas\n",
        "    real_accuracy = tf.reduce_mean(tf.cast(disc_real_output > 0.5, tf.float32))\n",
        "    fake_accuracy = tf.reduce_mean(tf.cast(disc_generated_output <= 0.5, tf.float32))\n",
        "    disc_accuracy = (real_accuracy + fake_accuracy) / 2\n",
        "\n",
        "    # Registra os resultados no TensorBoard\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)\n",
        "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)\n",
        "        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step//1000)\n",
        "        tf.summary.scalar('disc_loss', disc_loss, step=step//1000)\n",
        "        tf.summary.scalar('disc_accuracy', disc_accuracy, step=step//1000)\n",
        "\n",
        "    # Retorna as perdas e acur√°cias\n",
        "    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, disc_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEmvp6UL2ZmI"
      },
      "outputs": [],
      "source": [
        "# Realiza a valida√ß√£o do modelo\n",
        "@tf.function\n",
        "def val_step(input_image, target, step):\n",
        "    # Gera a sa√≠da do gerador\n",
        "    gen_output = generator(input_image, training=False)\n",
        "\n",
        "    # Calcula as sa√≠das do discriminador para as imagens reais e geradas\n",
        "    disc_real_output = discriminator([input_image, target], training=False)\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=False)\n",
        "\n",
        "    # Calcula as perdas do gerador e do discriminador\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    # Calcula a acur√°cia do discriminador para as imagens reais e geradas\n",
        "    real_accuracy = tf.reduce_mean(tf.cast(disc_real_output > 0.5, tf.float32))\n",
        "    fake_accuracy = tf.reduce_mean(tf.cast(disc_generated_output <= 0.5, tf.float32))\n",
        "    disc_accuracy = (real_accuracy + fake_accuracy) / 2\n",
        "\n",
        "    # Registra os resultados no TensorBoard\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('val_gen_total_loss', gen_total_loss, step=step//1000)\n",
        "        tf.summary.scalar('val_gen_gan_loss', gen_gan_loss, step=step//1000)\n",
        "        tf.summary.scalar('val_gen_l1_loss', gen_l1_loss, step=step//1000)\n",
        "        tf.summary.scalar('val_disc_loss', disc_loss, step=step//1000)\n",
        "        tf.summary.scalar('val_disc_accuracy', disc_accuracy, step=step//1000)\n",
        "\n",
        "    # Retorna as perdas e acur√°cias\n",
        "    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, disc_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbOfPuF4ZU9Y"
      },
      "outputs": [],
      "source": [
        "# Apaga checkpoints antigos caso um novo seja criado\n",
        "\n",
        "def remove_old_checkpoints(checkpoint_dir, keep_latest=1):\n",
        "    checkpoints = glob.glob(os.path.join(checkpoint_dir, \"ckpt-*\"))\n",
        "    checkpoints.sort()\n",
        "\n",
        "\n",
        "    for checkpoint in checkpoints[:-keep_latest]:\n",
        "        os.remove(checkpoint)\n",
        "        print(f\"Checkpoint removed: {checkpoint}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7iBvoPFMdPm"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "def fit(train_ds, val_ds, steps):\n",
        "    start = time.time()\n",
        "\n",
        "    # Listas para armazenar m√©tricas de treinamento\n",
        "    gen_total_loss_list = []\n",
        "    gen_gan_loss_list = []\n",
        "    gen_l1_loss_list = []\n",
        "    disc_loss_list = []\n",
        "    disc_accuracy_list = []\n",
        "\n",
        "    # Listas para armazenar m√©tricas de valida√ß√£o (ser√£o atualizadas apenas a cada 100 √©pocas)\n",
        "    val_gen_total_loss_list = []\n",
        "    val_gen_gan_loss_list = []\n",
        "    val_gen_l1_loss_list = []\n",
        "    val_disc_loss_list = []\n",
        "    val_disc_accuracy_list = []\n",
        "\n",
        "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "    if latest_checkpoint:\n",
        "        print(f\"Checkpoint encontrado: {latest_checkpoint}\")\n",
        "    else:\n",
        "        print(\"Nenhum checkpoint encontrado. O treinamento ser√° iniciado do zero.\")\n",
        "\n",
        "    for step, (input_image, target, file_path) in train_ds.repeat().take(steps).enumerate():\n",
        "        # Realiza o treinamento normal\n",
        "        gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, disc_accuracy = train_step(input_image, target, step)\n",
        "\n",
        "        # Salva m√©tricas de treinamento\n",
        "        gen_total_loss_list.append(gen_total_loss.numpy())\n",
        "        gen_gan_loss_list.append(gen_gan_loss.numpy())\n",
        "        gen_l1_loss_list.append(gen_l1_loss.numpy())\n",
        "        disc_loss_list.append(disc_loss.numpy())\n",
        "        disc_accuracy_list.append(disc_accuracy.numpy())\n",
        "\n",
        "        # Executa a valida√ß√£o APENAS a cada 100 √©pocas\n",
        "        if (step + 1) % 100 == 0:\n",
        "            val_gen_total_loss, val_gen_gan_loss, val_gen_l1_loss, val_disc_loss, val_disc_accuracy = 0, 0, 0, 0, 0\n",
        "            val_steps = 0\n",
        "\n",
        "            for val_input_image, val_target, val_path in val_ds:\n",
        "                v_gen_total_loss, v_gen_gan_loss, v_gen_l1_loss, v_disc_loss, v_disc_accuracy = val_step(val_input_image, val_target, step)\n",
        "\n",
        "                val_gen_total_loss += v_gen_total_loss\n",
        "                val_gen_gan_loss += v_gen_gan_loss\n",
        "                val_gen_l1_loss += v_gen_l1_loss\n",
        "                val_disc_loss += v_disc_loss\n",
        "                val_disc_accuracy += v_disc_accuracy\n",
        "                val_steps += 1\n",
        "\n",
        "            # Calcula m√©dias das m√©tricas de valida√ß√£o\n",
        "            val_gen_total_loss /= val_steps\n",
        "            val_gen_gan_loss /= val_steps\n",
        "            val_gen_l1_loss /= val_steps\n",
        "            val_disc_loss /= val_steps\n",
        "            val_disc_accuracy /= val_steps\n",
        "\n",
        "            # Adiciona os valores m√©dios √†s listas de valida√ß√£o\n",
        "            val_gen_total_loss_list.append(val_gen_total_loss.numpy())\n",
        "            val_gen_gan_loss_list.append(val_gen_gan_loss.numpy())\n",
        "            val_gen_l1_loss_list.append(val_gen_l1_loss.numpy())\n",
        "            val_disc_loss_list.append(val_disc_loss.numpy())\n",
        "            val_disc_accuracy_list.append(val_disc_accuracy.numpy())\n",
        "\n",
        "            print(f\"Valida√ß√£o na √©poca {step + 1}: Gen Loss {val_gen_total_loss.numpy():.4f}, Disc Loss {val_disc_loss.numpy():.4f}\")\n",
        "\n",
        "        print(f\"{step.numpy()}/{steps - 1}\")\n",
        "\n",
        "        # Salva o checkpoint no final do treinamento\n",
        "        if step + 1 == int(steps * 1) and save_checkpoint == 1:\n",
        "            remove_old_checkpoints(checkpoint_dir, keep_latest=1)\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "            print(\"Checkpoint Salvo!\")\n",
        "\n",
        "    return {\n",
        "        \"steps\": steps,\n",
        "        \"train_metrics\": {\n",
        "            \"gen_total_loss\": gen_total_loss_list,\n",
        "            \"gen_gan_loss\": gen_gan_loss_list,\n",
        "            \"gen_l1_loss\": gen_l1_loss_list,\n",
        "            \"disc_loss\": disc_loss_list,\n",
        "            \"disc_accuracy\": disc_accuracy_list,\n",
        "        },\n",
        "        \"val_metrics\": {\n",
        "            \"gen_total_loss\": val_gen_total_loss_list,\n",
        "            \"gen_gan_loss\": val_gen_gan_loss_list,\n",
        "            \"gen_l1_loss\": val_gen_l1_loss_list,\n",
        "            \"disc_loss\": val_disc_loss_list,\n",
        "            \"disc_accuracy\": val_disc_accuracy_list,\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bok5d2SOMfX8"
      },
      "outputs": [],
      "source": [
        "# Apresenta os tipos de cada um dos conjuntos de dados\n",
        "if mode == 'train':\n",
        "    print(\"BUFFER_SIZE = \", BUFFER_SIZE)\n",
        "    print(\"Type train_dataset: \", type(train_dataset))\n",
        "    print(\"Shape train_dataset: \", np.shape(train_dataset))\n",
        "    print(\"Type test_dataset: \", type(test_dataset))\n",
        "    print(\"Shape test_dataset: \", np.shape(test_dataset))\n",
        "    print(\"Type val_dataset: \", type(val_dataset))\n",
        "    print(\"Shape val_dataset: \", np.shape(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHG1BRFwMgZh"
      },
      "outputs": [],
      "source": [
        "# Aplica o modelo as conjuntos de treino e valida√ß√£o obtendo as m√©tricas de qualidade\n",
        "if mode == 'train':\n",
        "    print('Starting the training stage.')\n",
        "    epochs = 10000\n",
        "    ##################\n",
        "    result = fit(train_dataset, val_dataset, steps=epochs)\n",
        "\n",
        "    # steps, gen_total_loss_list, gen_gan_loss_list, gen_l1_loss_list, disc_loss_list, disc_accuracy_list, val_gen_total_loss_list, val_gen_gan_loss_list, val_gen_l1_loss_list, val_disc_loss_list, val_disc_accuracy_list = fit(train_dataset, val_dataset, steps=epochs)\n",
        "    ##################\n",
        "    print('Training finished.')\n",
        "\n",
        "    gen_total_loss_list = result[\"train_metrics\"][\"gen_total_loss\"]\n",
        "    gen_gan_loss_list = result[\"train_metrics\"][\"gen_gan_loss\"]\n",
        "    gen_l1_loss_list = result[\"train_metrics\"][\"gen_l1_loss\"]\n",
        "    disc_loss_list = result[\"train_metrics\"][\"disc_loss\"]\n",
        "    disc_accuracy_list = result[\"train_metrics\"][\"disc_accuracy\"]\n",
        "\n",
        "    # M√©tricas de valida√ß√£o\n",
        "    val_gen_total_loss_list = result[\"val_metrics\"][\"gen_total_loss\"]\n",
        "    val_gen_gan_loss_list = result[\"val_metrics\"][\"gen_gan_loss\"]\n",
        "    val_gen_l1_loss_list = result[\"val_metrics\"][\"gen_l1_loss\"]\n",
        "    val_disc_loss_list = result[\"val_metrics\"][\"disc_loss\"]\n",
        "    val_disc_accuracy_list = result[\"val_metrics\"][\"disc_accuracy\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# if mode == 'train':\n",
        "#     # Restoring the latest checkpoint in checkpoint_dir\n",
        "#     checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xKd_jZ9uv3j"
      },
      "outputs": [],
      "source": [
        "# Salva o modelo\n",
        "\n",
        "if mode == 'train':\n",
        "    generator.save('/content/gdrive/MyDrive/Mestrado/C√≥digos/Modelo/generator_model.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vluRnESf9kMl"
      },
      "outputs": [],
      "source": [
        "# Salva as iamgens de qualquer plot\n",
        "def save_plot(x, y_train, y_val, xlabel, ylabel, title, filename, label1, label2):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y_train, label=label1)\n",
        "    plt.plot(x, y_val, label=label2)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(plot_folder, filename), dpi=300, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JRZI1VbxdiH"
      },
      "outputs": [],
      "source": [
        "def pad_with_zeros(arr1, arr2):\n",
        "    len1, len2 = len(arr1), len(arr2)\n",
        "\n",
        "    if len1 >= len2:\n",
        "        return arr1\n",
        "\n",
        "    # Criar um array de sa√≠da preenchido com zeros\n",
        "    new_arr = np.zeros(len2, dtype=int)\n",
        "\n",
        "    # Determinar os √≠ndices onde os valores de arr1 ser√£o inseridos\n",
        "    insert_positions = np.linspace(0, len2 - 1, num=len1, dtype=int)\n",
        "\n",
        "    # Inserir os valores de arr1 nas posi√ß√µes calculadas\n",
        "    for i, pos in enumerate(insert_positions):\n",
        "        new_arr[pos] = arr1[i]\n",
        "\n",
        "    return new_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "colaPBe0uql-"
      },
      "outputs": [],
      "source": [
        "# Salva as imagens dos plots de loss para o gerador e para o discriminador\n",
        "\n",
        "if mode == 'train':\n",
        "\n",
        "    plot_folder = '/content/gdrive/MyDrive/Mestrado/C√≥digos/Plot/'\n",
        "    if not os.path.exists(plot_folder):\n",
        "        os.makedirs(plot_folder)\n",
        "\n",
        "    # Imprime informa√ß√µes de debug\n",
        "    print(\"type gen: \", type(gen_total_loss_list))\n",
        "    print(\"type disc: \", type(disc_loss_list))\n",
        "    print(\"type val: \", type(val_gen_total_loss_list))\n",
        "    print(\"size gen: \", len(gen_total_loss_list))\n",
        "    print(\"size disc: \", len(disc_loss_list))\n",
        "    print(\"size val: \", len(val_gen_total_loss_list))\n",
        "    print(val_gen_total_loss_list)\n",
        "\n",
        "    # Define os steps\n",
        "    steps = list(range(len(gen_total_loss_list)))\n",
        "\n",
        "    val_gen_total_loss_list = pad_with_zeros(val_gen_total_loss_list, gen_total_loss_list)\n",
        "    val_disc_loss_list = pad_with_zeros(val_disc_loss_list, disc_loss_list)\n",
        "\n",
        "    print(\"Ajuste no tamanho\")\n",
        "    print(\"type gen: \", type(gen_total_loss_list))\n",
        "    print(\"type disc: \", type(disc_loss_list))\n",
        "    print(\"type val: \", type(val_gen_total_loss_list))\n",
        "    print(\"size gen: \", len(gen_total_loss_list))\n",
        "    print(\"size disc: \", len(disc_loss_list))\n",
        "    print(\"size val: \", len(val_gen_total_loss_list))\n",
        "    print(val_gen_total_loss_list)\n",
        "\n",
        "    # Salva gr√°ficos\n",
        "    save_plot(steps, gen_total_loss_list, val_gen_total_loss_list, 'Step', 'Loss', 'Generator Total Loss', 'Generator_Total_Loss.png', 'Treinamento', 'Valida√ß√£o')\n",
        "    save_plot(steps, disc_loss_list, val_disc_loss_list, 'Step', 'Loss', 'Discriminator Loss', 'Discriminator_Loss.png', 'Treinamento', 'Valida√ß√£o')\n",
        "    save_plot(steps, gen_total_loss_list, disc_loss_list, 'Step', 'Loss', 'GenxDisc Loss', 'GenxDisc_Loss.png', 'Generator Loss', 'Discriminator Loss')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Salva dados em CSV\n",
        "    data = {\n",
        "        'Step': steps,\n",
        "        'Generator Total Loss': gen_total_loss_list,\n",
        "        'Validation Generator Total Loss': val_gen_total_loss_list,\n",
        "        'Discriminator Loss': disc_loss_list,\n",
        "        'Validation Discriminator Loss': val_disc_loss_list,\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Caminho do arquivo CSV\n",
        "    csv_file = os.path.join(plot_folder, 'training_metrics.csv')\n",
        "\n",
        "    # Salva o DataFrame no arquivo CSV\n",
        "    df.to_csv(csv_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MAfSYMgMlpB"
      },
      "outputs": [],
      "source": [
        "# Deleta os conte√∫dos de uma pasta\n",
        "\n",
        "\n",
        "def delete_folder_content(folder_path):\n",
        "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "        contents = os.listdir(folder_path)\n",
        "\n",
        "        for content in contents:\n",
        "            content_path = os.path.join(folder_path, content)\n",
        "            if os.path.isfile(content_path):\n",
        "                os.remove(content_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FGei_T3B_rK"
      },
      "outputs": [],
      "source": [
        "# Carrega o modelo\n",
        "\n",
        "model_save_path = '/content/gdrive/MyDrive/Mestrado/C√≥digos/Modelo/generator_model.keras'\n",
        "\n",
        "if mode == 'test':\n",
        "    from tensorflow.keras.models import load_model\n",
        "    generator = load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peduqgUZMnVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9b021c-5420-42a8-aaeb-5a9be288aa29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "# Uso o conjunto de teste para observar o funcionamento do modelo e salva essas imagens em uma pasta\n",
        "\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "\n",
        "    k = 0\n",
        "\n",
        "    n_test = count_files(dataset_path + 'test')\n",
        "\n",
        "    print(n_test)\n",
        "\n",
        "    # n_test = 10\n",
        "\n",
        "    image_folder = '/content/gdrive/MyDrive/Mestrado/CoÃÅdigos/Generated Images'\n",
        "    delete_folder_content(image_folder)\n",
        "    file_path = '/content/gdrive/MyDrive/Mestrado/CoÃÅdigos/Generated Images/Image'\n",
        "    for inp, tar, fil in test_dataset.take(n_test):\n",
        "        generate_images_file(generator, inp, tar, file_path + str(k) + '_', k, comp = 0)\n",
        "        k += 1\n",
        "        if show_predicted_images_after_training:\n",
        "            generate_images(generator, inp, tar, file_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
