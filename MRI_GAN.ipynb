{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmasF4qVHXbc"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import cupy\n",
        "except:\n",
        "    pass\n",
        "import datetime\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "#from mri_cs import column2matrix, matrix2column, prefiltering, radial_lines_samples_rows\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import pydot\n",
        "from scipy.io import loadmat\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBCPl3Q8PxYy",
        "outputId": "eb3874b5-90f6-4a0b-ed23-dec6045f66c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjxIqTBgKc8P"
      },
      "outputs": [],
      "source": [
        "mode = 'test'\n",
        "save_checkpoint = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlrWWr2lANID"
      },
      "outputs": [],
      "source": [
        "# Conta o número de arquivos em uma pasta\n",
        "\n",
        "def count_files(folder):\n",
        "    items = os.listdir(folder)\n",
        "\n",
        "    files = [item for item in items if os.path.isfile(os.path.join(folder, item))]\n",
        "\n",
        "    return len(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJWKGv5ZKf6y",
        "outputId": "561d6738-30e9-4feb-888f-43e4c3e10203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train images:  1500\n"
          ]
        }
      ],
      "source": [
        "if mode == 'train' or mode == 'test':\n",
        "    show_intermediate_images = False\n",
        "    show_predicted_images_after_training = False\n",
        "\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "    dataset_name = \"birn_anatomical_part\"\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "    dataset_path = '/content/gdrive/MyDrive/Mestrado/Códigos/datasets/' + dataset_name + '/'\n",
        "    n_cont = count_files(dataset_path + 'train')\n",
        "    print(\"Number of train images: \", n_cont)\n",
        "\n",
        "\n",
        "if mode == 'train':\n",
        "    sample_image = tf.io.read_file(dataset_path + 'train/1.png')\n",
        "    sample_image = tf.io.decode_png(sample_image, channels=3)\n",
        "    print(sample_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1B5vdE3JiRD"
      },
      "outputs": [],
      "source": [
        "if mode == 'train':\n",
        "    if show_intermediate_images:\n",
        "        plt.figure()\n",
        "        plt.imshow(sample_image)\n",
        "\n",
        "def load(image_file):\n",
        "    # Read and decode an image file to a uint8 tensor\n",
        "    print(\"Start Load\")\n",
        "    print(\"real_file type: \", type(image_file))\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.io.decode_png(image, channels=3)\n",
        "    print(\"END STEP 1 LOAD\")\n",
        "\n",
        "    # Split each image tensor into two tensors:\n",
        "    # - one with a real building facade image\n",
        "    # - one with an architecture label image\n",
        "    w = tf.shape(image)[1]\n",
        "    w = w // 2\n",
        "    input_image = image[:, w:, :]\n",
        "    real_image = image[:, :w, :]\n",
        "\n",
        "    # Convert both images to float32 tensors\n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "    file_path = image_file\n",
        "    print(\"input_image type: \", type(input_image))\n",
        "    print(\"real_image type: \", type(real_image))\n",
        "    print(\"file_path type: \", type(file_path))\n",
        "    print(\"END STEP 2 LOAD\")\n",
        "    return input_image, real_image, file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Fabh-5K0ke",
        "outputId": "6ef82d5c-79cb-4f13-d534-da559e71ec5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Load\n",
            "real_file type:  <class 'str'>\n",
            "END STEP 1 LOAD\n",
            "input_image type:  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "real_image type:  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "file_path type:  <class 'str'>\n",
            "END STEP 2 LOAD\n",
            "Image Height:  512\n",
            "Image Width:  512\n"
          ]
        }
      ],
      "source": [
        "if mode == 'train' or mode == 'test':\n",
        "    input1, output1, img_path = load(dataset_path + 'test/1.png')\n",
        "    IMG_HEIGHT, IMG_WIDTH = input1.shape[:2]\n",
        "    print(\"Image Height: \", IMG_HEIGHT)\n",
        "    print(\"Image Width: \", IMG_WIDTH)\n",
        "    if show_intermediate_images:\n",
        "        plt.figure()\n",
        "        plt.imshow(input1 / 255.0)\n",
        "        plt.title(\"Example of image to be used in the cGAN input\")\n",
        "        plt.show()\n",
        "        plt.figure()\n",
        "        plt.imshow(output1 / 255.0)\n",
        "        plt.title(\"Example of image to be generated in the cGAN output\")\n",
        "        plt.show()\n",
        "\n",
        "if mode == 'train':\n",
        "    inp, re, img_path = load(dataset_path + 'train/1.png')\n",
        "    print(\"Input Shape: \", inp.shape)\n",
        "    if show_intermediate_images:\n",
        "        # Casting to int for matplotlib to display the images\n",
        "        plt.figure()\n",
        "        plt.imshow(inp / 255.0)\n",
        "        plt.title(\"Example of image to be used in the cGAN input\")\n",
        "        plt.show()\n",
        "        plt.figure()\n",
        "        plt.imshow(re / 255.0)\n",
        "        plt.title(\"Example of image to be generated in the cGAN output\")\n",
        "        plt.show()\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "    # The facade training set consist of 400 images\n",
        "    BUFFER_SIZE = int(n_cont)\n",
        "    # The batch size of 1 produced better results for the U-Net in the original pix2pix experiment\n",
        "    BATCH_SIZE = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3PH_luIK1XH"
      },
      "outputs": [],
      "source": [
        "# Esse conjunto de funções aumenta o tamanho das imagens e depois corta trechos da imagem aumentada do tamanho da imagem original, isso permite\n",
        "#maior variedade de dados de treinamento inserindo leves variaçoes na imagem\n",
        "\n",
        "def resize(input_image, real_image, height, width):\n",
        "    input_image = tf.image.resize(input_image, [height, width],\n",
        "    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    real_image = tf.image.resize(real_image, [height, width],\n",
        "    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def random_crop(input_image, real_image):\n",
        "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "    cropped_image = tf.image.random_crop(\\\n",
        "    stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    return cropped_image[0], cropped_image[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhOyfpj5LOTU"
      },
      "outputs": [],
      "source": [
        "# Faz um teste, abrindo a segunda imagem e realizando as opreações resize e random_crop\n",
        "if mode == 'train':\n",
        "    input1, output1, img_path = load(dataset_path + 'train/2.png')\n",
        "    input1, output1 = resize(input1, output1, IMG_HEIGHT + 30, IMG_WIDTH + 30)\n",
        "    input1, output1 = random_crop(input1, output1)\n",
        "    if show_intermediate_images:\n",
        "        plt.figure()\n",
        "        plt.imshow(input1 / 255.0)\n",
        "        plt.title(\"Example of image to be used in the cGAN input\")\n",
        "        plt.show()\n",
        "        plt.figure()\n",
        "        plt.imshow(output1 / 255.0)\n",
        "        plt.title(\"Example of image to be generated in the cGAN output\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2LCcxiXLP0Q"
      },
      "outputs": [],
      "source": [
        "# Normaliza os valores para ficarem entre -1 e 1\n",
        "def normalize(input_image, real_image):\n",
        "\n",
        "    input_image = (input_image / 127.5) - 1\n",
        "    real_image = (real_image / 127.5) - 1\n",
        "\n",
        "    return input_image, real_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TptePVoHLRnC"
      },
      "outputs": [],
      "source": [
        "# Usa as funções resize e random_crop  para aumentar a variedade das imagens além de espelhar algumas imagens.\n",
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "\n",
        "    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT + 30, IMG_WIDTH + 30)\n",
        "    input_image, real_image = random_crop(input_image, real_image)\n",
        "\n",
        "    # Aleatoriamente espelha algumas imagens em volta do eixo vertical, aumentando a variedade e diminuindo overfitting\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        real_image = tf.image.flip_left_right(real_image)\n",
        "    return input_image, real_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZVgJZNTHhFe"
      },
      "outputs": [],
      "source": [
        "if mode == 'train':\n",
        "    data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "                                            tf.keras.layers.RandomRotation(0.2),])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsfoHL2FHiBD"
      },
      "outputs": [],
      "source": [
        "def augment_images(input, target):\n",
        "    input = data_augmentation(input)\n",
        "    target = data_augmentation(target)\n",
        "    return input, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xSBufGXLRnf"
      },
      "outputs": [],
      "source": [
        "# Visualiza a imagem após aplicar a função random_jitter\n",
        "if mode == 'train':\n",
        "    if show_intermediate_images:\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        for i in range(4):\n",
        "            rj_inp, rj_re = random_jitter(inp, re)\n",
        "            plt.subplot(2, 2, i + 1)\n",
        "            plt.imshow(rj_inp / 255.0)\n",
        "            plt.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmK3W0OQLUIR"
      },
      "outputs": [],
      "source": [
        "# As três funções abaixo carregam os conjuntos de dados de treino, teste e validação respectivamente, realizando as operações de random_jitter e normalização\n",
        "def load_image_train(image_file):\n",
        "    input_image, real_image, file_path = load(image_file)\n",
        "    input_image, real_image = random_jitter(input_image, real_image)\n",
        "    # input_image, real_image = augment_images(input_image, real_image) Rotacionar as imagens estava criando muito ruído e atrapalhando o treinamento pois as imagens sempre estão na mesma posição\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "    return input_image, real_image, file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc_sEgpMLXQq"
      },
      "outputs": [],
      "source": [
        "def load_image_test(image_file):\n",
        "    input_image, real_image, file_path = load(image_file)\n",
        "    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT, IMG_WIDTH)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "    return input_image, real_image, file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um5KykRoEN3c"
      },
      "outputs": [],
      "source": [
        "def load_image_val(image_file):\n",
        "    input_image, real_image, file_path = load(image_file)\n",
        "    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT, IMG_WIDTH)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "    return input_image, real_image, file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L_-B6DiLa6M",
        "outputId": "ead1df16-b8a9-491a-ba30-1ade4c737792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Load\n",
            "real_file type:  <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "END STEP 1 LOAD\n",
            "input_image type:  <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "real_image type:  <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "file_path type:  <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "END STEP 2 LOAD\n"
          ]
        }
      ],
      "source": [
        "# Mapeia e separa os conjuntos em batches\n",
        "if mode == 'train':\n",
        "    train_dataset = tf.data.Dataset.list_files(dataset_path + 'train/*.png')\n",
        "    train_dataset = train_dataset.map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    try:\n",
        "        val_dataset = tf.data.Dataset.list_files(dataset_path + 'val/*.png')\n",
        "    except tf.errors.InvalidArgumentError:\n",
        "        print(\"ERROR\")\n",
        "    val_dataset = val_dataset.map(load_image_val, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "    val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "    try:\n",
        "        test_dataset = tf.data.Dataset.list_files(dataset_path + 'test/*.png')\n",
        "    except tf.errors.InvalidArgumentError:\n",
        "        print(\"ERROR\")\n",
        "    test_dataset = test_dataset.map(load_image_test)\n",
        "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "    test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "if mode == 'train':\n",
        "    OUTPUT_CHANNELS = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Waq2F6x5LhYj"
      },
      "outputs": [],
      "source": [
        "# Função que cria o modelo downsample\n",
        "def downsample(filters, size, apply_batchnorm = True, kernel_regularizer=None):\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "\n",
        "    result.add(tf.keras.layers.Conv2D(filters, size, strides = 2, padding = 'same',\n",
        "                                        kernel_initializer = initializer,\n",
        "                                        kernel_regularizer = kernel_regularizer,\n",
        "                                        use_bias = not apply_batchnorm))\n",
        "\n",
        "    if apply_batchnorm:\n",
        "        result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z4CE2EZLh5a"
      },
      "outputs": [],
      "source": [
        "# Apresenta uma imagem após aplicar o downsample\n",
        "\n",
        "if mode == 'train':\n",
        "    down_model = downsample(3, 4)\n",
        "    down_result = down_model(tf.expand_dims(inp, 0))\n",
        "    print(inp.shape)\n",
        "    print(down_result.shape)\n",
        "    print(np.min(inp))\n",
        "    print(np.max(inp))\n",
        "    print(np.min(down_result))\n",
        "    print(np.max(down_result))\n",
        "    x = down_result[0, :, :, :]\n",
        "    x -= np.min(x)\n",
        "    x /= np.max(x)\n",
        "    print(np.min(inp))\n",
        "    print(np.max(inp))\n",
        "    print(np.min(x))\n",
        "    print(np.max(x))\n",
        "    if show_intermediate_images:\n",
        "        plt.imshow(inp / 255.0)\n",
        "        plt.imshow(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH5P3QdiLkDO"
      },
      "outputs": [],
      "source": [
        "# Apresenta uma imagem que será usada como input da GAN, com a realização de operações de resize e random_crop\n",
        "# Também apresenta uma imagem após a realização do downsample\n",
        "\n",
        "if mode == 'train':\n",
        "    input1, output1, img_path = load(dataset_path + 'train/1.png')\n",
        "    input1, output1 = resize(input1, output1, IMG_HEIGHT + 30, IMG_WIDTH + 30)\n",
        "    input1, output1 = random_crop(input1, output1)\n",
        "    if show_intermediate_images:\n",
        "        plt.figure()\n",
        "        plt.imshow(input1 / 255.0)\n",
        "        plt.title(\"Example of image to be used in the cGAN input\")\n",
        "        plt.show()\n",
        "        input1, output1 = normalize(input1, output1)\n",
        "        down_result = down_model(tf.expand_dims(input1, 0))\n",
        "        # plt.figure()\n",
        "        # plt.imshow((down_result + 1) / 2 * 255.0)\n",
        "        # plt.title(\"Example of the image after the downsample model (before training)\")\n",
        "        # plt.show()\n",
        "        print(input1.shape)\n",
        "        print(down_result.shape)\n",
        "        x = np.zeros(shape = (down_result.shape[1], down_result.shape[2], down_result.shape[3]))\n",
        "        print(x.shape)\n",
        "        x[:, :, :] = down_result[0, :, :, :]\n",
        "        plt.figure()\n",
        "        plt.imshow(x)\n",
        "        plt.title(\"Example of the downsample module output (before training)\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyu1p7FZLl9M"
      },
      "outputs": [],
      "source": [
        "# Função que cria o modelo upsample\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "\n",
        "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                padding='same',\n",
        "                kernel_initializer=initializer,\n",
        "                use_bias=False))\n",
        "\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "        result.add(tf.keras.layers.ReLU())\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diQzquFmLuVJ"
      },
      "outputs": [],
      "source": [
        "# Cria um modelo upsample\n",
        "if mode == 'train':\n",
        "    up_model = upsample(3, 4)\n",
        "    up_result = up_model(down_result)\n",
        "    print (up_result.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_Cxk78ZLwWR"
      },
      "outputs": [],
      "source": [
        "# Cria o gerador baseado em um modelo U-net com uma sequência de downsamples e upsamples que evidencia as características da imagem\n",
        "def Generator():\n",
        "    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3])  # Entrada do modelo\n",
        "\n",
        "    # Define o down_stack (as camadas de downsampling)\n",
        "    down_stack = [\n",
        "        downsample(64, 4, apply_batchnorm=False),  # (batch_size, IMG_HEIGHT/2, IMG_WIDTH/2, 64)\n",
        "        downsample(128, 4),                        # (batch_size, IMG_HEIGHT/4, IMG_WIDTH/4, 128)\n",
        "        downsample(256, 4),                        # (batch_size, IMG_HEIGHT/8, IMG_WIDTH/8, 256)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/16, IMG_WIDTH/16, 512)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/32, IMG_WIDTH/32, 512)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/64, IMG_WIDTH/64, 512)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/128, IMG_WIDTH/128, 512)\n",
        "        downsample(512, 4),                        # (batch_size, IMG_HEIGHT/256, IMG_WIDTH/256, 512)\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Passa a entrada pelas camadas de downsampling\n",
        "    x = inputs\n",
        "    skips = []  # Para armazenar conexões de salto (skip connections)\n",
        "    for down in down_stack:\n",
        "        x = down(x)  # Chama cada camada no down_stack\n",
        "        skips.append(x)\n",
        "\n",
        "    # Remove a última conexão de salto, pois ela não é usada no upsampling\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Define o up_stack (as camadas de upsampling)\n",
        "    up_stack = [\n",
        "        upsample(512, 4, apply_dropout=True),  # (batch_size, IMG_HEIGHT/128, IMG_WIDTH/128, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (batch_size, IMG_HEIGHT/64, IMG_WIDTH/64, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (batch_size, IMG_HEIGHT/32, IMG_WIDTH/32, 1024)\n",
        "        upsample(512, 4),                      # (batch_size, IMG_HEIGHT/16, IMG_WIDTH/16, 1024)\n",
        "        upsample(256, 4),                      # (batch_size, IMG_HEIGHT/8, IMG_WIDTH/8, 512)\n",
        "        upsample(128, 4),                      # (batch_size, IMG_HEIGHT/4, IMG_WIDTH/4, 256)\n",
        "        upsample(64, 4),                       # (batch_size, IMG_HEIGHT/2, IMG_WIDTH/2, 128)\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    # Passa pelos upsampling layers e conecta com os skips\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = tf.keras.layers.Concatenate()([x, skip])\n",
        "\n",
        "    # Última camada de saída\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv2DTranspose(\n",
        "        3, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh',\n",
        "        kernel_regularizer=tf.keras.regularizers.L2(1e-4)  # Adiciona regularização L2\n",
        "    )  # (batch_size, IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywZUj1QeL74Q"
      },
      "outputs": [],
      "source": [
        "# Cria uma visualização gráfica do modelo gerador\n",
        "# if mode == 'train':\n",
        "#     generator = Generator()\n",
        "#     tf.keras.utils.plot_model(generator, to_file = 'generator.png', show_shapes=True, dpi=64)\n",
        "#     if show_intermediate_images:\n",
        "#         x = plt.imread('generator.png')\n",
        "#         plt.imshow(x, cmap = 'gray')\n",
        "#         plt.show()\n",
        "\n",
        "\n",
        "# Aplica o modelo a uma imagem exemplo e apresenta o resultado\n",
        "if mode == 'train':\n",
        "    generator = Generator()\n",
        "    generator.summary()\n",
        "    gen_output = generator(inp[tf.newaxis, ...], training=False)\n",
        "    if show_intermediate_images:\n",
        "        plt.imshow(gen_output[0, ...])\n",
        "\n",
        "\n",
        "if mode == 'train':\n",
        "    plot_path = os.path.join('/content/gdrive/MyDrive/Mestrado/Códigos/Plot/', \"unet_diagram.png\")\n",
        "    plot_model(generator, to_file=plot_path, show_shapes=True, expand_nested=True)\n",
        "\n",
        "    print(f\"Diagrama salvo em: {plot_path}\")\n",
        "\n",
        "\n",
        "if mode == 'train':\n",
        "    LAMBDA = 150\n",
        "\n",
        "if mode == 'train':\n",
        "    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtB0qur8blMU"
      },
      "outputs": [],
      "source": [
        "# retorna os valores de loss do generator que são usados para ajustar a rede\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        " gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        " l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        " total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        " return total_gen_loss, gan_loss, l1_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhmchusRMB9N"
      },
      "outputs": [],
      "source": [
        "# Função que cria o modelo discriminador\n",
        "def Discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    # Define as entradas com base em IMG_HEIGHT e IMG_WIDTH\n",
        "    inp = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3], name='input_image')\n",
        "    tar = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3], name='target_image')\n",
        "\n",
        "    # Calcula a diferença absoluta entre as imagens\n",
        "    diff = tf.keras.layers.Subtract()([tar, inp])  # Calcula tar - inp\n",
        "\n",
        "    # Concatena as imagens de entrada, alvo e a diferença\n",
        "    x = tf.keras.layers.concatenate([inp, tar, diff])  # (batch_size, IMG_HEIGHT, IMG_WIDTH, 9)\n",
        "\n",
        "    # Define o down_stack com dropout e regularização L2\n",
        "    down1 = downsample(64, 4, apply_batchnorm=False)(x)\n",
        "    down2 = tf.keras.layers.Dropout(0.5)(downsample(128, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down1))\n",
        "    down3 = tf.keras.layers.Dropout(0.5)(downsample(256, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down2))\n",
        "    down4 = downsample(512, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down3)\n",
        "    down5 = tf.keras.layers.Dropout(0.5)(downsample(512, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down4))\n",
        "    down6 = downsample(512, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down5)\n",
        "    down7 = tf.keras.layers.Dropout(0.5)(downsample(512, 4, kernel_regularizer=tf.keras.regularizers.L2(1e-4))(down6))\n",
        "\n",
        "    # Zero padding para manter as dimensões ao aplicar convoluções finais\n",
        "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down7)\n",
        "    conv = tf.keras.layers.Conv2D(\n",
        "        512, 4, strides=1, kernel_initializer=initializer, use_bias=False,\n",
        "        kernel_regularizer=tf.keras.regularizers.L2(1e-4)\n",
        "    )(zero_pad1)\n",
        "\n",
        "    # Batch normalization e ativação Leaky ReLU\n",
        "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "    # Segunda camada de zero padding e convolução final para classificar real/fake\n",
        "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)\n",
        "    last = tf.keras.layers.Conv2D(\n",
        "        1, 4, strides=1, kernel_initializer=initializer,\n",
        "        kernel_regularizer=tf.keras.regularizers.L2(1e-4)\n",
        "    )(zero_pad2)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtIbZqUnMEfa"
      },
      "outputs": [],
      "source": [
        "# visualiza o modelo discriminador de forma gráfica\n",
        "if mode == 'train':\n",
        "    discriminator = Discriminator()\n",
        "    discriminator.summary()\n",
        "#     plot_path = os.path.join('/content/gdrive/MyDrive/Mestrado/Códigos/Plot/', \"disc_diagram.png\")\n",
        "#     plot_model(discriminator, to_file=plot_path, show_shapes=True, expand_nested=True)\n",
        "\n",
        "#     print(f\"Diagrama salvo em: {plot_path}\")\n",
        "\n",
        "\n",
        "# Apresenta a saida do discriminador de forma gráfica\n",
        "# if mode == 'train':\n",
        "#     disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)\n",
        "#     if show_intermediate_images:\n",
        "#         plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
        "#         plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1NQ2Hy4MIsF"
      },
      "outputs": [],
      "source": [
        "# Calcula a perda (loss) do modelo discriminador\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        " real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        " generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        " total_disc_loss = real_loss + generated_loss\n",
        "\n",
        " return total_disc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2D9201kMNM5"
      },
      "outputs": [],
      "source": [
        "# Instância o otimizador Adam para os modelos\n",
        "\n",
        "if mode == 'train':\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "\n",
        "# Cria um objeto que salva o estado dos modelos e dos otimizadores em checkpoints\n",
        "if mode == 'train':\n",
        "    checkpoint_dir = '/content/gdrive/MyDrive/Mestrado/Códigos/Checkpoints'\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                    discriminator_optimizer=discriminator_optimizer,\n",
        "                                    generator=generator,\n",
        "                                    discriminator=discriminator)\n",
        "\n",
        "\n",
        "    # latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    # if latest_checkpoint and os.path.exists(latest_checkpoint + \".index\"):\n",
        "    #     checkpoint.restore(latest_checkpoint).expect_partial()\n",
        "    #     print(f\"Checkpoint restored from: {latest_checkpoint}\")\n",
        "    # else:\n",
        "    #     print(\"Checkpoint not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHNdfo4zMOvF"
      },
      "outputs": [],
      "source": [
        "# Gera o conjunto de imagens resultado em uma única imagem\n",
        "\n",
        "def generate_images(model, test_input, tar, save_path):\n",
        " prediction = model(test_input, training=True)\n",
        " plt.figure(figsize=(15, 15))\n",
        "\n",
        " display_list = [test_input[0], tar[0], prediction[0]]\n",
        " title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        " for i in range(3):\n",
        "     plt.subplot(1, 3, i+1)\n",
        "     plt.title(title[i])\n",
        "     # Getting the pixel values in the [0, 1] range to plot.\n",
        "     plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "     plt.axis('off')\n",
        "     #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6QSlbc6MQkb"
      },
      "outputs": [],
      "source": [
        "def generate_images_file(model, test_input, tar, file_name, n, comp = 0):\n",
        "    prediction = model(test_input, training=True)\n",
        "\n",
        "    display_list = [test_input[0], tar[0], prediction[0]]\n",
        "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "    # 🔹 Salvando as imagens individuais no tamanho correto (512x512)\n",
        "    for i in range(3):\n",
        "        save_path = f\"{file_name}_{title[i]}.png\"\n",
        "        mpimg.imsave(save_path, display_list[i].numpy() * 0.5 + 0.5, cmap='gray')\n",
        "\n",
        "    # 🔹 Criando a imagem combinada com as 3 imagens lado a lado\n",
        "\n",
        "    if comp == 1:\n",
        "        for i in range(3):\n",
        "            plt.subplot(1, 3, i+1)\n",
        "            plt.title(title[i])\n",
        "            # Getting the pixel values in the [0, 1] range to plot.\n",
        "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "            plt.axis('off')\n",
        "            if i == 2:\n",
        "                plt.savefig(file_name + '.png', dpi=300, bbox_inches = 'tight')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9UsFLmLMT3E"
      },
      "outputs": [],
      "source": [
        "# if mode == 'train':\n",
        "#     if show_intermediate_images:\n",
        "#         for example_input, example_target in test_dataset.take(1):\n",
        "#          generate_images(generator, example_input, example_target)\n",
        "\n",
        "# Cria logs com detalhamento dos treinamentos\n",
        "if mode == 'train':\n",
        "    log_dir=\"logs/\"\n",
        "    summary_writer = tf.summary.create_file_writer(\n",
        "     log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chK8H1C_MWcq"
      },
      "outputs": [],
      "source": [
        "# Realiza o treinamento do modelo\n",
        "@tf.function\n",
        "def train_step(input_image, target, step):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Gera a imagem de saída do gerador\n",
        "        gen_output = generator(input_image, training=True)\n",
        "\n",
        "        # Recebe os pares de imagem reais e falsos com os respectivos rótulos\n",
        "        disc_real_output = discriminator([input_image, target], training=True)\n",
        "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
        "\n",
        "        # Calcula as perdas do gerador e do discriminador\n",
        "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "        # Calcula os gradientes e aplica a otimização\n",
        "        generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
        "        discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
        "\n",
        "    # Calcula a acurácia do discriminador para as imagens reais e geradas\n",
        "    real_accuracy = tf.reduce_mean(tf.cast(disc_real_output > 0.5, tf.float32))\n",
        "    fake_accuracy = tf.reduce_mean(tf.cast(disc_generated_output <= 0.5, tf.float32))\n",
        "    disc_accuracy = (real_accuracy + fake_accuracy) / 2\n",
        "\n",
        "    # Registra os resultados no TensorBoard\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)\n",
        "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)\n",
        "        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step//1000)\n",
        "        tf.summary.scalar('disc_loss', disc_loss, step=step//1000)\n",
        "        tf.summary.scalar('disc_accuracy', disc_accuracy, step=step//1000)\n",
        "\n",
        "    # Retorna as perdas e acurácias\n",
        "    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, disc_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEmvp6UL2ZmI"
      },
      "outputs": [],
      "source": [
        "# Realiza a validação do modelo\n",
        "@tf.function\n",
        "def val_step(input_image, target, step):\n",
        "    # Gera a saída do gerador\n",
        "    gen_output = generator(input_image, training=False)\n",
        "\n",
        "    # Calcula as saídas do discriminador para as imagens reais e geradas\n",
        "    disc_real_output = discriminator([input_image, target], training=False)\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=False)\n",
        "\n",
        "    # Calcula as perdas do gerador e do discriminador\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    # Calcula a acurácia do discriminador para as imagens reais e geradas\n",
        "    real_accuracy = tf.reduce_mean(tf.cast(disc_real_output > 0.5, tf.float32))\n",
        "    fake_accuracy = tf.reduce_mean(tf.cast(disc_generated_output <= 0.5, tf.float32))\n",
        "    disc_accuracy = (real_accuracy + fake_accuracy) / 2\n",
        "\n",
        "    # Registra os resultados no TensorBoard\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('val_gen_total_loss', gen_total_loss, step=step//1000)\n",
        "        tf.summary.scalar('val_gen_gan_loss', gen_gan_loss, step=step//1000)\n",
        "        tf.summary.scalar('val_gen_l1_loss', gen_l1_loss, step=step//1000)\n",
        "        tf.summary.scalar('val_disc_loss', disc_loss, step=step//1000)\n",
        "        tf.summary.scalar('val_disc_accuracy', disc_accuracy, step=step//1000)\n",
        "\n",
        "    # Retorna as perdas e acurácias\n",
        "    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, disc_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbOfPuF4ZU9Y"
      },
      "outputs": [],
      "source": [
        "# Apaga checkpoints antigos caso um novo seja criado\n",
        "\n",
        "def remove_old_checkpoints(checkpoint_dir, keep_latest=1):\n",
        "    checkpoints = glob.glob(os.path.join(checkpoint_dir, \"ckpt-*\"))\n",
        "    checkpoints.sort()\n",
        "\n",
        "\n",
        "    for checkpoint in checkpoints[:-keep_latest]:\n",
        "        os.remove(checkpoint)\n",
        "        print(f\"Checkpoint removed: {checkpoint}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7iBvoPFMdPm"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "def fit(train_ds, val_ds, steps):\n",
        "    start = time.time()\n",
        "\n",
        "    # Listas para armazenar métricas de treinamento\n",
        "    gen_total_loss_list = []\n",
        "    gen_gan_loss_list = []\n",
        "    gen_l1_loss_list = []\n",
        "    disc_loss_list = []\n",
        "    disc_accuracy_list = []\n",
        "\n",
        "    # Listas para armazenar métricas de validação (serão atualizadas apenas a cada 100 épocas)\n",
        "    val_gen_total_loss_list = []\n",
        "    val_gen_gan_loss_list = []\n",
        "    val_gen_l1_loss_list = []\n",
        "    val_disc_loss_list = []\n",
        "    val_disc_accuracy_list = []\n",
        "\n",
        "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "    if latest_checkpoint:\n",
        "        print(f\"Checkpoint encontrado: {latest_checkpoint}\")\n",
        "    else:\n",
        "        print(\"Nenhum checkpoint encontrado. O treinamento será iniciado do zero.\")\n",
        "\n",
        "    for step, (input_image, target, file_path) in train_ds.repeat().take(steps).enumerate():\n",
        "        # Realiza o treinamento normal\n",
        "        gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss, disc_accuracy = train_step(input_image, target, step)\n",
        "\n",
        "        # Salva métricas de treinamento\n",
        "        gen_total_loss_list.append(gen_total_loss.numpy())\n",
        "        gen_gan_loss_list.append(gen_gan_loss.numpy())\n",
        "        gen_l1_loss_list.append(gen_l1_loss.numpy())\n",
        "        disc_loss_list.append(disc_loss.numpy())\n",
        "        disc_accuracy_list.append(disc_accuracy.numpy())\n",
        "\n",
        "        # Executa a validação APENAS a cada 100 épocas\n",
        "        if (step + 1) % 100 == 0:\n",
        "            val_gen_total_loss, val_gen_gan_loss, val_gen_l1_loss, val_disc_loss, val_disc_accuracy = 0, 0, 0, 0, 0\n",
        "            val_steps = 0\n",
        "\n",
        "            for val_input_image, val_target, val_path in val_ds:\n",
        "                v_gen_total_loss, v_gen_gan_loss, v_gen_l1_loss, v_disc_loss, v_disc_accuracy = val_step(val_input_image, val_target, step)\n",
        "\n",
        "                val_gen_total_loss += v_gen_total_loss\n",
        "                val_gen_gan_loss += v_gen_gan_loss\n",
        "                val_gen_l1_loss += v_gen_l1_loss\n",
        "                val_disc_loss += v_disc_loss\n",
        "                val_disc_accuracy += v_disc_accuracy\n",
        "                val_steps += 1\n",
        "\n",
        "            # Calcula médias das métricas de validação\n",
        "            val_gen_total_loss /= val_steps\n",
        "            val_gen_gan_loss /= val_steps\n",
        "            val_gen_l1_loss /= val_steps\n",
        "            val_disc_loss /= val_steps\n",
        "            val_disc_accuracy /= val_steps\n",
        "\n",
        "            # Adiciona os valores médios às listas de validação\n",
        "            val_gen_total_loss_list.append(val_gen_total_loss.numpy())\n",
        "            val_gen_gan_loss_list.append(val_gen_gan_loss.numpy())\n",
        "            val_gen_l1_loss_list.append(val_gen_l1_loss.numpy())\n",
        "            val_disc_loss_list.append(val_disc_loss.numpy())\n",
        "            val_disc_accuracy_list.append(val_disc_accuracy.numpy())\n",
        "\n",
        "            print(f\"Validação na época {step + 1}: Gen Loss {val_gen_total_loss.numpy():.4f}, Disc Loss {val_disc_loss.numpy():.4f}\")\n",
        "\n",
        "        print(f\"{step.numpy()}/{steps - 1}\")\n",
        "\n",
        "        # Salva o checkpoint no final do treinamento\n",
        "        if step + 1 == int(steps * 1) and save_checkpoint == 1:\n",
        "            remove_old_checkpoints(checkpoint_dir, keep_latest=1)\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "            print(\"Checkpoint Salvo!\")\n",
        "\n",
        "    return {\n",
        "        \"steps\": steps,\n",
        "        \"train_metrics\": {\n",
        "            \"gen_total_loss\": gen_total_loss_list,\n",
        "            \"gen_gan_loss\": gen_gan_loss_list,\n",
        "            \"gen_l1_loss\": gen_l1_loss_list,\n",
        "            \"disc_loss\": disc_loss_list,\n",
        "            \"disc_accuracy\": disc_accuracy_list,\n",
        "        },\n",
        "        \"val_metrics\": {\n",
        "            \"gen_total_loss\": val_gen_total_loss_list,\n",
        "            \"gen_gan_loss\": val_gen_gan_loss_list,\n",
        "            \"gen_l1_loss\": val_gen_l1_loss_list,\n",
        "            \"disc_loss\": val_disc_loss_list,\n",
        "            \"disc_accuracy\": val_disc_accuracy_list,\n",
        "        }\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bok5d2SOMfX8"
      },
      "outputs": [],
      "source": [
        "# Apresenta os tipos de cada um dos conjuntos de dados\n",
        "if mode == 'train':\n",
        "    print(\"BUFFER_SIZE = \", BUFFER_SIZE)\n",
        "    print(\"Type train_dataset: \", type(train_dataset))\n",
        "    print(\"Shape train_dataset: \", np.shape(train_dataset))\n",
        "    print(\"Type test_dataset: \", type(test_dataset))\n",
        "    print(\"Shape test_dataset: \", np.shape(test_dataset))\n",
        "    print(\"Type val_dataset: \", type(val_dataset))\n",
        "    print(\"Shape val_dataset: \", np.shape(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHG1BRFwMgZh"
      },
      "outputs": [],
      "source": [
        "# Aplica o modelo as conjuntos de treino e validação obtendo as métricas de qualidade\n",
        "if mode == 'train':\n",
        "    print('Starting the training stage.')\n",
        "    epochs = 10000\n",
        "    ##################\n",
        "    result = fit(train_dataset, val_dataset, steps=epochs)\n",
        "\n",
        "    # steps, gen_total_loss_list, gen_gan_loss_list, gen_l1_loss_list, disc_loss_list, disc_accuracy_list, val_gen_total_loss_list, val_gen_gan_loss_list, val_gen_l1_loss_list, val_disc_loss_list, val_disc_accuracy_list = fit(train_dataset, val_dataset, steps=epochs)\n",
        "    ##################\n",
        "    print('Training finished.')\n",
        "\n",
        "    gen_total_loss_list = result[\"train_metrics\"][\"gen_total_loss\"]\n",
        "    gen_gan_loss_list = result[\"train_metrics\"][\"gen_gan_loss\"]\n",
        "    gen_l1_loss_list = result[\"train_metrics\"][\"gen_l1_loss\"]\n",
        "    disc_loss_list = result[\"train_metrics\"][\"disc_loss\"]\n",
        "    disc_accuracy_list = result[\"train_metrics\"][\"disc_accuracy\"]\n",
        "\n",
        "    # Métricas de validação\n",
        "    val_gen_total_loss_list = result[\"val_metrics\"][\"gen_total_loss\"]\n",
        "    val_gen_gan_loss_list = result[\"val_metrics\"][\"gen_gan_loss\"]\n",
        "    val_gen_l1_loss_list = result[\"val_metrics\"][\"gen_l1_loss\"]\n",
        "    val_disc_loss_list = result[\"val_metrics\"][\"disc_loss\"]\n",
        "    val_disc_accuracy_list = result[\"val_metrics\"][\"disc_accuracy\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# if mode == 'train':\n",
        "#     # Restoring the latest checkpoint in checkpoint_dir\n",
        "#     checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xKd_jZ9uv3j"
      },
      "outputs": [],
      "source": [
        "# Salva o modelo\n",
        "\n",
        "if mode == 'train':\n",
        "    generator.save('/content/gdrive/MyDrive/Mestrado/Códigos/Modelo/generator_model.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vluRnESf9kMl"
      },
      "outputs": [],
      "source": [
        "# Salva as iamgens de qualquer plot\n",
        "def save_plot(x, y_train, y_val, xlabel, ylabel, title, filename, label1, label2):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y_train, label=label1)\n",
        "    plt.plot(x, y_val, label=label2)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(plot_folder, filename), dpi=300, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JRZI1VbxdiH"
      },
      "outputs": [],
      "source": [
        "def pad_with_zeros(arr1, arr2):\n",
        "    len1, len2 = len(arr1), len(arr2)\n",
        "\n",
        "    if len1 >= len2:\n",
        "        return arr1\n",
        "\n",
        "    # Criar um array de saída preenchido com zeros\n",
        "    new_arr = np.zeros(len2, dtype=int)\n",
        "\n",
        "    # Determinar os índices onde os valores de arr1 serão inseridos\n",
        "    insert_positions = np.linspace(0, len2 - 1, num=len1, dtype=int)\n",
        "\n",
        "    # Inserir os valores de arr1 nas posições calculadas\n",
        "    for i, pos in enumerate(insert_positions):\n",
        "        new_arr[pos] = arr1[i]\n",
        "\n",
        "    return new_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "colaPBe0uql-"
      },
      "outputs": [],
      "source": [
        "# Salva as imagens dos plots de loss para o gerador e para o discriminador\n",
        "\n",
        "if mode == 'train':\n",
        "\n",
        "    plot_folder = '/content/gdrive/MyDrive/Mestrado/Códigos/Plot/'\n",
        "    if not os.path.exists(plot_folder):\n",
        "        os.makedirs(plot_folder)\n",
        "\n",
        "    # Imprime informações de debug\n",
        "    print(\"type gen: \", type(gen_total_loss_list))\n",
        "    print(\"type disc: \", type(disc_loss_list))\n",
        "    print(\"type val: \", type(val_gen_total_loss_list))\n",
        "    print(\"size gen: \", len(gen_total_loss_list))\n",
        "    print(\"size disc: \", len(disc_loss_list))\n",
        "    print(\"size val: \", len(val_gen_total_loss_list))\n",
        "    print(val_gen_total_loss_list)\n",
        "\n",
        "    # Define os steps\n",
        "    steps = list(range(len(gen_total_loss_list)))\n",
        "\n",
        "    val_gen_total_loss_list = pad_with_zeros(val_gen_total_loss_list, gen_total_loss_list)\n",
        "    val_disc_loss_list = pad_with_zeros(val_disc_loss_list, disc_loss_list)\n",
        "\n",
        "    print(\"Ajuste no tamanho\")\n",
        "    print(\"type gen: \", type(gen_total_loss_list))\n",
        "    print(\"type disc: \", type(disc_loss_list))\n",
        "    print(\"type val: \", type(val_gen_total_loss_list))\n",
        "    print(\"size gen: \", len(gen_total_loss_list))\n",
        "    print(\"size disc: \", len(disc_loss_list))\n",
        "    print(\"size val: \", len(val_gen_total_loss_list))\n",
        "    print(val_gen_total_loss_list)\n",
        "\n",
        "    # Salva gráficos\n",
        "    save_plot(steps, gen_total_loss_list, val_gen_total_loss_list, 'Step', 'Loss', 'Generator Total Loss', 'Generator_Total_Loss.png', 'Treinamento', 'Validação')\n",
        "    save_plot(steps, disc_loss_list, val_disc_loss_list, 'Step', 'Loss', 'Discriminator Loss', 'Discriminator_Loss.png', 'Treinamento', 'Validação')\n",
        "    save_plot(steps, gen_total_loss_list, disc_loss_list, 'Step', 'Loss', 'GenxDisc Loss', 'GenxDisc_Loss.png', 'Generator Loss', 'Discriminator Loss')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Salva dados em CSV\n",
        "    data = {\n",
        "        'Step': steps,\n",
        "        'Generator Total Loss': gen_total_loss_list,\n",
        "        'Validation Generator Total Loss': val_gen_total_loss_list,\n",
        "        'Discriminator Loss': disc_loss_list,\n",
        "        'Validation Discriminator Loss': val_disc_loss_list,\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Caminho do arquivo CSV\n",
        "    csv_file = os.path.join(plot_folder, 'training_metrics.csv')\n",
        "\n",
        "    # Salva o DataFrame no arquivo CSV\n",
        "    df.to_csv(csv_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MAfSYMgMlpB"
      },
      "outputs": [],
      "source": [
        "# Deleta os conteúdos de uma pasta\n",
        "\n",
        "\n",
        "def delete_folder_content(folder_path):\n",
        "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "        contents = os.listdir(folder_path)\n",
        "\n",
        "        for content in contents:\n",
        "            content_path = os.path.join(folder_path, content)\n",
        "            if os.path.isfile(content_path):\n",
        "                os.remove(content_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FGei_T3B_rK"
      },
      "outputs": [],
      "source": [
        "# Carrega o modelo\n",
        "\n",
        "model_save_path = '/content/gdrive/MyDrive/Mestrado/Códigos/Modelo/generator_model.keras'\n",
        "\n",
        "if mode == 'test':\n",
        "    from tensorflow.keras.models import load_model\n",
        "    generator = load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peduqgUZMnVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9b021c-5420-42a8-aaeb-5a9be288aa29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "# Uso o conjunto de teste para observar o funcionamento do modelo e salva essas imagens em uma pasta\n",
        "\n",
        "\n",
        "if mode == 'train' or mode == 'test':\n",
        "\n",
        "    k = 0\n",
        "\n",
        "    n_test = count_files(dataset_path + 'test')\n",
        "\n",
        "    print(n_test)\n",
        "\n",
        "    # n_test = 10\n",
        "\n",
        "    image_folder = '/content/gdrive/MyDrive/Mestrado/Códigos/Generated Images'\n",
        "    delete_folder_content(image_folder)\n",
        "    file_path = '/content/gdrive/MyDrive/Mestrado/Códigos/Generated Images/Image'\n",
        "    for inp, tar, fil in test_dataset.take(n_test):\n",
        "        generate_images_file(generator, inp, tar, file_path + str(k) + '_', k, comp = 0)\n",
        "        k += 1\n",
        "        if show_predicted_images_after_training:\n",
        "            generate_images(generator, inp, tar, file_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
